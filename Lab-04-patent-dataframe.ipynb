{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Keep US patents with a real state and alias POSTATE -> STATE for joining\n",
    "# create data frame that stores columns patent, country, and POSTATE\n",
    "patents_us = (\n",
    "    patents.select(\n",
    "        F.col(\"PATENT\").cast(\"long\").alias(\"PATENT\"),\n",
    "        F.col(\"COUNTRY\"),\n",
    "        F.col(\"POSTATE\").alias(\"STATE\")\n",
    "    )\n",
    "    .withColumn(\"STATE\", F.when(F.length(\"STATE\")==0, None).otherwise(F.col(\"STATE\")))\n",
    "    .filter((F.col(\"COUNTRY\")==\"US\") & F.col(\"STATE\").isNotNull())\n",
    ")\n",
    "\n",
    "# Build lookup for the cited side: CITED patent id -> CITED_STATE\n",
    "cited_states  = patents_us.select(F.col(\"PATENT\").alias(\"CITED\"),  F.col(\"STATE\").alias(\"CITED_STATE\"))\n",
    "# Build lookup for the citing side: CITING patent id -> CITING_STATE\n",
    "citing_states = patents_us.select(F.col(\"PATENT\").alias(\"CITING\"), F.col(\"STATE\").alias(\"CITING_STATE\"))\n",
    "\n",
    "# Join the citation pairs with both lookups(above) so each row has both states\n",
    "joined = (\n",
    "    citations\n",
    "    .join(cited_states,  on=\"CITED\",  how=\"left\")\n",
    "    .join(citing_states, on=\"CITING\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Compute a bool flag to represent if matching states\n",
    "same_counts = (\n",
    "    joined\n",
    "    # Flag as 1 only when both states exist and are equal, otherwise 0\n",
    "    .withColumn(\n",
    "        \"is_same\",\n",
    "        F.when(\n",
    "            (F.col(\"CITING_STATE\").isNotNull()) &\n",
    "            (F.col(\"CITED_STATE\").isNotNull()) &\n",
    "            (F.col(\"CITING_STATE\")==F.col(\"CITED_STATE\")), 1\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    .groupBy(\"CITING\")\n",
    "    .agg(F.sum(\"is_same\").cast(\"int\").alias(\"same_state_citations\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for a clean join and desired output column name\n",
    "counts_for_join = same_counts.select(\n",
    "    F.col(\"CITING\").alias(\"PATENT\"),\n",
    "    F.col(\"same_state_citations\").cast(\"int\").alias(\"SAME_STATE\")\n",
    ")\n",
    "\n",
    "# Left-join onto the full patents data frame, fill missing with 0\n",
    "patents_with_same = (\n",
    "    patents\n",
    "    .join(counts_for_join, on=\"PATENT\", how=\"left\")\n",
    "    .fillna({\"SAME_STATE\": 0})\n",
    ")\n",
    "\n",
    "# Reorder columns so SAME_STATE is last, like the screenshot\n",
    "cols_in_order = patents.columns + [\"SAME_STATE\"]\n",
    "patents_with_same_ordered = patents_with_same.select(*cols_in_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|SAME_STATE|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1.0     |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125       |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0.0     |0.0     |NULL    |NULL    |103       |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1.0     |NULL   |0.7415  |NULL    |5.0     |0.0085  |0.0083  |NULL    |NULL    |100       |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1.0     |NULL   |0.7442  |NULL    |5.1102  |0.0     |0.0     |NULL    |NULL    |98        |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1.0     |NULL   |0.7397  |NULL    |5.181   |0.0     |0.0     |NULL    |NULL    |96        |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1.0     |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96        |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1.0     |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94        |\n",
      "|5739256|1998 |13983|1995   |US     |CA     |70060   |2      |15    |528   |1  |15    |453  |0       |1.0     |NULL   |0.8232  |NULL    |15.1104 |0.1124  |0.1082  |NULL    |NULL    |90        |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7403  |NULL    |8.3595  |0.0     |0.0     |NULL    |NULL    |90        |\n",
      "|5925042|1999 |14445|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7382  |NULL    |8.3471  |0.0     |0.0     |NULL    |NULL    |90        |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort patents by SAME_STATE (highest first), and break ties by PATENT id (lowest first)\n",
    "top10 = (\n",
    "    patents_with_same_ordered\n",
    "    .orderBy(F.col(\"SAME_STATE\").desc(), F.col(\"PATENT\").asc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "top10.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
