{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our session as described in the tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Keep US patents with a real state and alias POSTATE -> STATE for joining\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# create data frame that stores columns patent, country, and POSTATE\u001b[39;00m\n\u001b[1;32m      5\u001b[0m patents_us \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mpatents\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      7\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATENT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATENT\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOUNTRY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m         F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mwhen(F\u001b[38;5;241m.\u001b[39mlength(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39motherwise(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mfilter((F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOUNTRY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNotNull())\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Build lookup for the cited side: CITED patent id -> CITED_STATE\u001b[39;00m\n\u001b[1;32m     16\u001b[0m cited_states  \u001b[38;5;241m=\u001b[39m patents_us\u001b[38;5;241m.\u001b[39mselect(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATENT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCITED\u001b[39m\u001b[38;5;124m\"\u001b[39m),  F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCITED_STATE\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patents' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Keep US patents with a real state and alias POSTATE -> STATE for joining\n",
    "# create data frame that stores columns patent, country, and POSTATE\n",
    "patents_us = (\n",
    "    patents.select(\n",
    "        F.col(\"PATENT\").cast(\"long\").alias(\"PATENT\"),\n",
    "        F.col(\"COUNTRY\"),\n",
    "        F.col(\"POSTATE\").alias(\"STATE\")\n",
    "    )\n",
    "    .withColumn(\"STATE\", F.when(F.length(\"STATE\")==0, None).otherwise(F.col(\"STATE\")))\n",
    "    .filter((F.col(\"COUNTRY\")==\"US\") & F.col(\"STATE\").isNotNull())\n",
    ")\n",
    "\n",
    "# Build lookup for the cited side: CITED patent id -> CITED_STATE\n",
    "cited_states  = patents_us.select(F.col(\"PATENT\").alias(\"CITED\"),  F.col(\"STATE\").alias(\"CITED_STATE\"))\n",
    "# Build lookup for the citing side: CITING patent id -> CITING_STATE\n",
    "citing_states = patents_us.select(F.col(\"PATENT\").alias(\"CITING\"), F.col(\"STATE\").alias(\"CITING_STATE\"))\n",
    "\n",
    "# Join the citation pairs with both lookups(above) so each row has both states\n",
    "joined = (\n",
    "    citations\n",
    "    .join(cited_states,  on=\"CITED\",  how=\"left\")\n",
    "    .join(citing_states, on=\"CITING\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Compute a bool flag to represent if matching states\n",
    "same_counts = (\n",
    "    joined\n",
    "    # Flag as 1 only when both states exist and are equal, otherwise 0\n",
    "    .withColumn(\n",
    "        \"is_same\",\n",
    "        F.when(\n",
    "            (F.col(\"CITING_STATE\").isNotNull()) &\n",
    "            (F.col(\"CITED_STATE\").isNotNull()) &\n",
    "            (F.col(\"CITING_STATE\")==F.col(\"CITED_STATE\")), 1\n",
    "        ).otherwise(0)\n",
    "    )\n",
    "    .groupBy(\"CITING\")\n",
    "    .agg(F.sum(\"is_same\").cast(\"int\").alias(\"same_state_citations\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for a clean join and desired output column name\n",
    "counts_for_join = same_counts.select(\n",
    "    F.col(\"CITING\").alias(\"PATENT\"),\n",
    "    F.col(\"same_state_citations\").cast(\"int\").alias(\"SAME_STATE\")\n",
    ")\n",
    "\n",
    "# Left-join onto the full patents data frame, fill missing with 0\n",
    "patents_with_same = (\n",
    "    patents\n",
    "    .join(counts_for_join, on=\"PATENT\", how=\"left\")\n",
    "    .fillna({\"SAME_STATE\": 0})\n",
    ")\n",
    "\n",
    "# Reorder columns so SAME_STATE is last, like the screenshot\n",
    "cols_in_order = patents.columns + [\"SAME_STATE\"]\n",
    "patents_with_same_ordered = patents_with_same.select(*cols_in_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort patents by SAME_STATE (highest first), and break ties by PATENT id (lowest first)\n",
    "top10 = (\n",
    "    patents_with_same_ordered\n",
    "    .orderBy(F.col(\"SAME_STATE\").desc(), F.col(\"PATENT\").asc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "top10.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
